 Honourable members, honoured guests, good evening and welcome to the first event of Hillary Term 2023 and the first event of the 200th anniversary year of the Oxford Union. Two hundred years ago, a group of students met in a small room in Christchurch, determined to have discussion free from the restrictions of the university. And two centuries later, we proudly continue this tradition by providing our members across the globe with opportunities to question their most fundamentally held beliefs and by standing up for free speech and expression. It brings me great pleasure to welcome Mr. Peter Thiel to give the inaugural address of the Oxford Union's bicentenary year. Mr. Teal is an American technology entrepreneur and investor. He co-founded PayPal and Palantir, made the first outside investment in Facebook, and has funded companies like LinkedIn and Yelp. Mr. Teal also founded the Teal Foundation, which works to advance technological progress and long-term thinking via funding non-profit research into artificial intelligence. life extension, and sea setting. Ladies and gentlemen, please join me in welcoming Mr. Peter Thiel. Well, Charlie, thank you so much for that terrific introduction, and a lot of different things to cover. I'm always reminded of a question, a colleague of mine like to ask, what is the antonym of diversity? What word is the single antonym of diversity? And university. And I think it's such a great honor and privilege here to speak here at the Oxford Union, where for 200 years people have been thinking about the crisis of the university, the crisis of the West, the crisis of classical liberalism. There are elements of this that are, of course, timeless and eternal. And then, of course, there are parts of it that are always, you know, there's always sort of a kaleidoscopic, newness, and effervescence to it as well. You know, I framed my talk as anti-anti-anty-anty-classical liberalism. So, you know, a double negative that's kind of a positive. A quadruple negative is also kind of a positive. and I'm going to try to sort of outline as I see the argument, as well as the best arguments against the university, classical liberalism, you know, sort of the free Western world, and at the end of the four negatives, I will still come down on something that I think is quite close to the values that would have animated the Oxford Union already 200 years ago. Now, I'll start with sort of a little bit of a historical anecdote. I was a student at Stanford University in the late 80s, early 90s. We had a lot of these crazy culture wars, you know, wars about the nature of the university. One of the ones where I sort of first came in some ways to sort of political awareness was an intense debate at Stanford about the Western Canon. A course called Western Culture was a required freshman course. In some ways was a debate about the course, but of course was all the also debate about the whole Western civilization. It represented, there was a famous protest that Jesse Jackson led at Stanford, hey, hey, ho, Western cultures got to go. It was a sort of referendum on the course and on our entire civilization. And I started one of these sort of independent, conservative, libertarian, alternate newspapers. We saw we should like investigate it. We needed to sort of describe the new curriculum. We need to figure out ways to denounce the new curriculum. And in the 88-89 term, one of the new classes called the sort of innovative new class was Europe and the Americas, which was not really a non-Western, but more an anti-Western sort of polemic. And you had sort of all these different authors. And I thought, you know, I should go to the bookstore and just read through the books and find people to illustrate the sort of parochiality and tendentiousness of this new curriculum. And I came on one book that somehow was almost too good to be true. was sort of summarized in an onion episode, everything that was a stereotype of everything was ridiculous about the new curriculum. It was a story of Iigurber Tomenchu. She was this Guatemalan native. And she's sort of been victimized by every vector of oppression imaginable. She was a poor, she was a peasant, she was an Indian, she was an orphan. And then she sort of achieved some sort of revolutionary communist consciousness in the course of this polemic book. She renounces marriage and motherhood. She makes plans for the May Day Parade. These are sort of the chapter titles of the book. You know, I wrote it up. And as so many of these debates in campus, it somehow was on some little very narrow issue that somehow kicked off a broader discussion. You know, as a 19-year-old junior at Stanford, I managed to get this reprinted in the Wall Street Journal. When some of the conservatives wrote books about the insanities of the universities in the late 80s, early 90s, one of the conservative people, the Stanford chapter was entitled Travels with Rigoberta. And so I sort of succeeded in turning her into an icon for this thing. And then, you know, then sort of four years, four years later, fall of 1992, I'm now clerking for a judge and driving to work in Atlanta, Georgia. And on the radio, it's, you know, we just have an announcement. We have someone who's just been selected for the Nobel Peace Prize. Someone nobody's ever heard of. it's Rigoberta Menchu. And I sort of realized at that moment that, yeah, I thought I was engaged in some kind of cosmic battle between the forces of good and evil. And actually, I had just been a two-bit actor in some left-wing drama where I had completed her victimization. And then, you know, I was the proximate cause of her getting her Nobel Peace Prize, but I think I was the but for cause. But for me, she would not have gotten it. And this is sort of sort of the odd feature of so many of these super intense debates where you sort of wonder, you know, what is it that is really going on, what is it that is perhaps really at stake that we should be talking about instead. And so if I look back, you know, on the debates at Stanford at the time, and at some extent these debates, I think they've been fought for, you know, for decades or centuries. If we took not the tendentious left wing, but let's say the sort of bureaucratic university perspective or the establishment perspective, what they would have said in the 1980s, what I think they still in many cases would say today, what they would have said in the 19th centuries, yeah, you have all these flaky debates in the humanities about reading Shakespeare and reading these books, but we're doing something much more important, The university is about progress, progress of knowledge, and this is especially true in the science and technology. That's where progress is happening, and we can have these side debates about Shakespeare or Rigoberta Menchu, but we're working on string theory and science and the sort of the relief of man's estate, Roger Bacon, Sir Francis Bacon, that whole thing, that's what the university is really all about. And I think this would have been the technocratic sort of defense, Stanford, given of itself in the 80s and 90s that, yes, the progress is continuing. It's continuing very rapidly. And this is what is sort of what is going on in our society. And that's what's fundamentally good. It's the Manhattan Project. It is the Apollo Space Program. It is the progress of humanity. And as long as we're doing that, you shouldn't, you can complain about these side shows, but it doesn't really matter. And so I think one of the debates that I came to, one of the perspectives I came to start to wonder about, though, in the late 90s, 2000s was, you know, yeah, we have so many of these culture wars are about these issues that everybody can understand, these books or, you know, Shakespeare versus Riggerber to mention or something like this, but perhaps things are just as, unhealthy in the sciences and in all these other disciplines that are after all far more narrowly the domains of experts you know you have a sense that if you substitute rigor bare dementia for Shakespeare something weird is going on if only 100 people in the world understand string theory and you have this sort of narrow group of guardians guarding themselves shouldn't the a priori assumption be that string theory is actually more corrupt than the humanities or the sciences are in many ways more corrupt than the humanities and and one of the one of the early people who drew my attention this was a professor at Stanford Bob Loughlin who got a Nobel Prize in physics in the late 1990s he sort of was a somewhat difficult person a friend of mine was getting his PhD work with Loughlin and but he had the supreme delusion that now that he had a Nobel prize in physics he had complete academic freedom and he would be allowed to investigate and talk about anything he wanted to and there are of course a lot of controversial topics in the sciences we could imagine. You could question climate change. You could talk about intelligence and genetics. You could talk about, you could talk about, you'd question Darwinism. I mean, there are all sorts of things that are quite taboo in the sciences, but he picked an area that was far worse, far more dangerous than any of those. And he was convinced that most of the scientists, even at a place like Stanford University, were engaged in borderline fraudulent research. They were stealing money from the taxpayers, And it needed to be investigated, it needed to be stopped. And, you know, I don't even sort of probably don't even need to tell you too much about how that movie ended. It sort of ended quite badly. He got defunded. His graduate students couldn't get PhDs anymore. And the kind of permanent suspicion I always have is that, you know, I wouldn't say it's automatically the case that if something is taboo, that it must be perfectly 100% accurate. But my suspicion is that if something is this taboo, this forbidden, you have to at least ask some sorts of questions. And the general thesis that I've been articulating in different for close to two decades is that there is something about science and technology that's not progressing as quickly. The specialization means that it's very hard to evaluate. You have all these different subspecialists that propagandize about themselves. The cancer researchers tell us they're going to occur cancer in five years, and they've been telling us that for 50 years, and the string theorists say they're the smartest people in the world, they know everything about physics, and we're about to have quantum computers, and on and on down the line. And yet, in many ways, we seem to have been kind of stuck. You know, if I go back to when I was an undergraduate, Stanford, almost all the engineering fields that one could have gone into would have been mistakes. It was a mistake to go into aeroastro engineering. It was a mistake to go into nuclear engineering. I think people already understood that by the 80s. These fields were stuck, they were outlawed, they weren't going to advance, you weren't going to make any progress, mechanical engineering, chemical engineering. All these things were bad ideas. The one that still held up pretty well in the late 80s, early 90s, for another decade, was electrical engineering, semiconductors, and then probably the one very silly field that actually did kind of work was computer science. And I always think that when you have fields that include science, that's always a tell that you have an inferiority complex because you don't need to call it physical science or chemical sciences, physics or chemistry, but it's computer science like political science or climate science. It's sort of like a deep sense of inferiority. And yet these people who had relatively bad math genes and went into this sort of very, very degenerate field called computer science. This was the one thing that had kind of worked the last 30, 35 years. And we had some sort of progress around this world of bits, computers, internet, mobile internet, you know, maybe I'll really dislike that word. And there are probably ways that even that progress has somewhat stalled out or become less utopian in the last decade. But for the last 40 or 50 years, outside the world of bits, it has been a story of general stagnation. And then not just in the fields, not just in terms of, you know, no big breakthroughs. But of course, also, you know, if we try to measure it economically, we have this very, odd situation in the UK or the US where for the first time in decades and centuries beyond count, the younger generation has lower economic expectations than their parents. And this is just very oddly doesn't fit with a sort of Kurtzwillian, Panglossian accelerationism, the singularity's near. And all you need to do is sit back and eat some popcorn and watch the movie the future run full. So there's something about the stagnation problem that runs quite deep, seems to be quite multifaceted. I sort of tend to date it back to something like the early 70s, the oil shocks, the inflation, a time when, you know, money no longer grew on trees because we didn't have this incredible tailwind of scientific and technological progress that was just advancing on its own. So, yeah, to recap where we are on the argument, the rebuttal to the rebuttal to classical liberalism, the rebuttal to classical liberalism is just, we don't need to do the humanities, we don't need to ask questions about the university, about the whole, we can just focus, we can just tell people to be organized, disciplined, and work on the sciences, sort of like the way the New York Times wrote about the Manhattan Project in 1945, sort of paraphrasing it was sort of, you know, there are these sort of free market, libertarian type people who think that, you know, who didn't believe that science should be run by the military, but, you know, they've, hopefully they're going to be quiet now because the military was able to, when they organized all these scientists, was able to invent this device, a nuclear bomb, in three and a half short years, which maybe if you left the prima donna scientists or their own devices would have taken 50 years or something like that. But anyway, New York Times doesn't write articles, op-eds like that anymore. And so there was, yeah, but there was sort of a certain non-classically, liberal organization regimentation that may have accelerated things for a while, but that now is completely exhausted. And so instead of getting into this debate about rigor, bare, dementia, Shakespeare, or string theory, the rebuttal to the rebuttal is they're not doing string theory, they're not doing science. It is all stalled out beyond belief. And this is, as I said, this is sort of the main frame of this debate that I've been giving for argument they've been making for something like the last two decades. And one of the questions I always get asked in this context is, well, why? Why did it stall out? What happened? What went wrong? And then my sort of slightly politically correct answer was always, well, you know, questions that start with why are always overdetermined. They're hard to answer. It's probably determined by a whole bunch of different things. And you know, you can say there's too much regulation. You know, the FDA regulates biotech too much. so it's hard to do things in biotech. You know, if you had as little regulation as you have for video games for new drugs, maybe we'd have more drugs. There's sort of the ways you can sort of blame education or government funding. But the single answer that I've come to believe as to why, why it is stalled out. And this is, and I believe this has now actually become the argument on the part of the universities, on the part of our zombie center-left establishment is something like science and technology are just too dangerous. And so what looks like it's a bug that things are no longer progressing is actually a feature. And we should be really, really happy that it's not progressing because science and technology are this giant trap that humanity is building for itself. And this is sort of what gets articulated in the world. in all sorts of different versions, existential risks, you know, all these ways that this, this, these things are back here. Probably, and again, you know, these timelines overlap in different ways, probably the original version, this was already involved nuclear power, nuclear weapons, thermonuclear weapons, the fear of nuclear war. It didn't probably hit people right away in 1945. But by the time you get to, you know, by the time you get to the late 60s, early 70s, you get someone like Charles Manson, the crazed person on LSD, goes around killing everybody in Los Angeles, you know, if you ask, what did he see? What did he see on his psychedelic drugs? Well, he figured out the world was coming to an end, and therefore you could be like Rus Kalnikov and Dostoevsky, and everything was permitted in this crazy world. You could do anything you could do to stop science, to slow it. down because it was just accelerating in this catastrophic way. And I think something like this is true of so many of these different areas that if we really think about it, they have sort of this dangerous, there is some sort of dangerous dual-use component that the space program was, you know, had the dual-use thing of just delivering ICBMs more quickly halfway around the planet. Or sort of the rhetorical question I'd like to ask in an emergency. American context is, you know, why can't we have tick or tape parades for individuals? Why can't we celebrate individuals anymore in sort of a ticker tape parade in New York? And why can't, let's pick left-wing individuals, individuals who fit the left-wing narrative. Why can't we have a tick-or-tape parade for the, you know, one or two, the key scientists who developed the MRNA vaccine? We're told this is this fantastic scientific technological breakthrough. Why can't we celebrate this? And my sort of cultural thesis is that it is immediately adjacent in people's minds to this great existential fear because the MRNA vaccines somehow remind us of this thing going on, the Wuhan lab that was called, had this Orwellian term, gain of function research, which sounds sort of like a bio-weapons program in disguise. And so, yes, if you can manipulate DNA, you can come up with these fantastic MRNA vaccine, vaccines, does that also mean that it's immediately adjacent to these sort of terrific, terrific, destructive weapons? Probably, you know, probably the area, the existential risk area that's the most, that's the most inside tech, if you say, again, tech is always a strange word where it used to mean all these areas, and it just came to mean IT computers, but within computers, probably the futuristic narrative is always around AI, artificial intelligence, artificial general intelligence, all these things. And 20 years ago, when I started getting involved in a lot of these things, the narrative was still, it was still generally positive, utopian. It was people thought, you know, it's kind of a dangerous technology. You know, if you build this computer that's as smart or smarter than any human being in the world, it's kind of dangerous, but we're gonna have to work really hard to make sure it's friends, that it's aligned with humans, and it was still sort of circa 2003, whatever misgivings people might have had about biotech or, you know, or rockets or nuclear power, they did not yet have about AI, and the AI narrative was still a generally positive utopian one. And there's sort of a strange way where this has completely flipped over the over the last decade or so. I was involved with a thing called the Singularity Institute, which pushed an sort of accelerationist utopian technology. We were progressing, we need to progress faster, we need to, of course, be a little bit careful. And I sort of remembered thinking to myself by 2015, I reconnected with some of these people, and it didn't feel like they were really pushing the AI thing as fast as before. And it had sort of devolved into some kind of escapist Burning Man camp. And you sort of got the sense that it had shifted from transhumanism to Luddite, something Luddite, where no, actually want to slow this down. It feels kind of dangerous. It's kind of a bad thing on net. And this finally, the suspicion, I think, was finally confirmed. You can look this up on the internet. I'm going to read this. It's from April 2022, less than a year ago. Eliezer Yudkowski, who's one of the sort of thought leaders of the sort of futurist AI. And it's a post from the Machine Intelligence Research Institute, and it's announcing a new death with dignity strategy. And so the short version of this, it's obvious at this point that humanity isn't going to solve the alignment problem of how to get the AI aligned with humans. or even try very hard, or even go out with much of a fight. Since survival is unattainable, we should shift the focus or efforts to helping humanity die with slightly more dignity. Again, I want to underscore, you don't deserve to die with a lot of dignity because you're not going to try very hard or even go out with much of a fight. But it is an extraordinary, it's an extraordinary way that the context has shifted. You know, I'm probably, and of course, you know, we can come up with other ones, probably the sort of the most mass market version of the sort of catastrophic existential risk is the climate change, the climate change one where, you know, I can just, you know, reference, probably reference Greta and the sort of autistic children's crusade. And it is, again, this is how the world is going to. to end this sort of runaway technology. And of course, you know, all these things I don't want to minimize, don't want to say they're not real, but it's striking how none of the solutions involve more technology. So the solution to climate change is not, you know, fusion reactors. The solution to, you know, nuclear weapons is not better anti-ballistic missile systems. This, you know, the solution to AI, you know, the solution to, you know, the solution to, you know, the solution to biotech is not accelerating the research even faster, it is just somehow stopping it altogether. And one is tempted to say that if anything, most of these people are insufficiently apocalyptic. You know, you want to get Greta, I'm trying to actually want to talk to her, but you want to get someone like Greta and tell her, you know, wow, you are a very complacent, non-apocalyptic person because you're only worried about this climate change thing and we also have this nuclear weapons thing that has made people go crazy for 70 years already. And we have, we have the AGI that's going to kill everybody at the singularity. And we have, you know, and we have the Wuhan lab, which you don't seem to be worried about at all, and the bioweapons. And we have, we have this happening on so many, so many different dimensions. And this is roughly where I think the zeitgeist is in, in 2020, 23, the sort of central left zombie zeitgeist as articulated by the universities. It is we're not doing science. We're proud that we're not doing science. We're proud that we're stopping science. We're proud that it has been slowed down as much as possible. And maybe a little bit unfair to pick on him, but I reference an Oxford professor, Nick Bostrom, who is at least smart enough to know that all these things add up and that these are all problems. And that's not just sort of one or the other. And I think of him as sort of a mouthpiece of the zeitgeist. And he sort of wrote this paper back in 2019. So this was pre-COVID before everyone went totally insane with COVID, so it doesn't have that excuse. But the Vulnerable World Hypothesis sort of, and it outlines all these different existential risks, climate change, nuclear weapons, runaway nanotechnology, the robots killing everybody, the AI killing everybody, runaway bioweapons, et cetera, et cetera. And there are four things that must be done to stabilize the world. Again, it's written in the most boring language possible. It's just channeling the zeitgeist. Number one, restrict technological development. Number two, ensure that there does not exist a large population of actors representing a wide and recognizably human distribution of motives. I believe that's diversity. But then he goes on to say that one and two, sort of don't quite happen on their own. And therefore, you need, number three, establish extremely effective, preventive policing. And number four, you need to establish effective global governance. And it does not quite use the word totalitarian, but it is basically, you know, the solution to the sort of existential, risks in our vulnerable world is to have a one-world totalitarian state. And this gets me to my concluding point. The anti-anti-anti-classical liberal argument is that if we are going to enumerate all these existential risks, and we have to talk about them, we have to discuss them, we have to think about them, we should not hide under the rock and pretend these things are not real, But we have to make the list complete, and I would include as a very, very serious existential risk, you know, the risk, if you end up with a one-world totalitarian state, that also counts as an existential risk. And it seems to me that we shouldn't get, we shouldn't be too short-sighted about that one. We should always fight that. That's something that always needs to be stopped. You know, I should not need to remind you that in the sort of quasi-mythological New Testament account, the slogan of the Antichrist is peace and safety. And that there is, you know, we're told that there's nothing worse than Armageddon, but perhaps there is. Perhaps we should fear the Antichrist, perhaps we should fear the one world totalitarian state more than Armageddon. And perhaps we should stick with some of the tried and true ideas of classical realism of this organization and this institution has been supporting for 200 years and keep going for another 200. Thank you very much. Before I hand over to questions from our audience, I'll talk about, I'll have a few questions for you. about the content of your speech. Start where you ended your speech on the threat of authoritarian government as a challenge or solution to the problems of technology. But you also enumerated the problems of specialized technological progress, which is something that has impacted public ability to engage your technology for decades. 40 years ago, most people would have been able to understand why their car was broken and potentially fix it themselves. Whereas now if a car breaks, it's most likely due to a software or electrical problem that no one will be able to deal with. Is technological development, rather than handing over power to an authoritarian state, not instead ever seeding ground to authoritarian technological companies? Well, there are all sorts of dimensions of this. I still tend to think the problem of the state is much bigger than the problem of big tech companies, or if there is a problem with big tech companies, it is just that they are very efficient vehicles for state power and that they will very effectively be used by the state. And yes, there's a problem with, you know, there's probably a problem with, you know, some kind of specialization. There's a problem with, you know, with problems with concentration. But I keep coming back to, I think the bigger problem is one of just, stagnation itself. And, you know, certainly stagnation is this very deep problem of late modernity. It's like the pin factory in Adam Smith, where you have 100 different people working on different parts of the pin. And this doesn't sound, it doesn't sound very charismatic. It might be efficient. But sort of if you tell people you're a small cog in a big machine and the future is you're going to become an ever smaller cog in an ever bigger machine, that's profoundly uncharismatic and they're problems with that. But the question I just keep coming back to is, is that even true? And, you know, we're told the story of specialization. We're told that all these narrow experts are making breathtaking progress. And I worry that the problem of hyper-specialization is just, there's no accountability, and it all just has become a crazed racket. Leading on from this question about the influence and authority that can be held by companies as a result of this. Very interested in fund lots of research to do with artificial intelligence, coding and algorithms. All algorithms are naturally written by individuals who have biases and beliefs of their own. Disproportionately, they are white men from the northern hemisphere. As these algorithms continue to play more and more of an influence in our lives, looking forward 50 or 100 years, do you think that these biases and beliefs will entrench themselves in the very fabric of our society? Well, it's, man, the, the AI topic is obviously a super, a super, a super broad one. The, what I, what I would say is I don't know if we actually need to get to the super futuristic versions of AI for it to be, for it to be problematic, where it's this super intelligent computer or, or something like that. The, the version of it that I think is the most. The most real and the most problematic is something like what you see in communist China, where it's fairly low-tech, but it is just this pervasive surveillance. You know, we can say it's the computers that are doing it, but it's always some people behind the computers, there's always a political question of sorts. And the rhetorical frame that I've come up with is, you know, you could, we have all sorts of debates whether AI is conscious or whether it's intelligent. or super intelligent. But if we avoid the political question of how it gets used in places like China, maybe it's merely evil. And maybe something can be merely evil. It's not conscious. It's not even intelligent. It's merely evil. But I would say, yeah, the problem is China far more than in the West. So the evilness is the individuals behind it? Or the technology itself? It's, it's, the technology tilts, it tilts towards surveillance. And then it's always, yeah, there's always some totalitarian, a set of a class party that can, that can stand behind it. You know, I don't think there's, it's, I don't think it's absolutely intrinsic to the technology, but the line I've used is that, you know, if people say that crypto is libertarian, which I might not even fully believe anymore, but if you were to say that crypto is libertarian, then why can't we say that AI is communist? It's not completely inherent in it, but it's a certain tendency in it. And while I am pro-acceleration, I'm pro-tech, I'm even pro-A-I, it is probably the one technology that I have the most misgivings about. I'll have a few questions about cryptocurrency and currency in general later. But an argument perhaps in favor of this rejection of technology, the Luddite case you presented, is that repeated studies across the United Kingdom, America, Canada, Western countries have shown that levels of individual satisfaction have not really increased and in some cases decreased since the 1960s, despite huge increases in ability or satisfaction of living, supposedly, technological advances. Why do you think this is? And if technological advances do not improve individual satisfaction, why are they worth pursuing? Well, you at least, in your question, you at least had the adverb supposedly. And I always think adverbs are very important because they're always a tell like in poker that the exact opposite is going on. So yes, we've been told supposedly that there is a lot of progress. I would want to question it. I believe the econ numbers more than the self-serving stories of the university presidents and the bureaucrats and the scientists and even the Silicon Valley Tech Company. So yes, there's been a narrow cone of progress around the world of bits and the Internet. it's not been enough to meaningfully increase the GDP per capita to meaningfully take our civilization in the next level. And that's why I would submit things feel that stuck. Now, I'm not a Luddite. I don't think we should embrace the stuckness. I don't think we should embrace the stagnation. I think the stagnation itself is ultimately unstable that, you know, we ultimately, you know, if we have a zero-sum society that will ultimately push us towards, you know, the kind of lockdowns, we've seen the last two, three years that I would argue in some ways we've had with respect to science and technology for 40 or 50 years and that it's deeply unhealthy at the end of the day. The Luddites, look, even if they were right about a lot of things, they ultimately are wrong. And you're ultimately, you're going to lose if nothing else than in the military context. You know, even if the Luddites are right about everything, you will always, you know, you will lose to China on hypersonic weapons or or space weapons or weapons in cis lunar space or robots armed with AI. And so probably there's something about the Luddite answer that's both sort of self-destructive and parochial at the same time. Given your comments about the Manhattan Project and your investment and engagement with Palantir, to what extent do you think that technological development is necessarily driven by war or a security dilemma? Well, it's been a, it's been a, it's been a big, big, big part of it. It's, it's obviously, it's obviously also been a big part of what went wrong with it. You know, if, you know, if, you know, if we had enough nuclear weapons to destroy the world 20 times over, you know, I'm not saying what Charles Manson did where he just went insane, started killing people was, you know, the only reasonable thing to do. But, but, but there was, there was a way that, you know, there was, there was a way that it, uh, it, uh, it drove a lot of progress and then it also deranged a lot of things. And we have to, yeah, I think we have to find some way to get back to the future where it's not dystopian, not Luddite, you know, not accelerating simply towards Armageddon, but also certainly not just the totalitarian lockdown. Is this partly why the stagnation you talked about scares you because you feel like stagnation in technological advancement in universities and the West, will directly lead to the downfall of American and Western supremacy? I think it's bad for the West, but I think even if there was no immediate external thing, I think it will derange our societies. You know, if you have no growth, then everything becomes a zero-sum racket where, you know, there has to be a loser for every winner. And I'm not sure that necessarily gets you to socialist redistribution, but it probably gets you to something very different from the kind of society we've had the last few years. So we've had this general stagnation and somehow, you know, we've kept going by some kind of inertia. But if it just stops, yeah, I think you end up with something much worse. So I don't trust that it's a stable outcome. Do you think this stagnation exists to the same extent in China and India and other growing parts of the world? I always think there's a difference between the developing and the developed worlds where the developing countries at least have or had some story of convergence with the developing world. There's some program where they can copy things and can catch up. But I think even if they succeeded at doing that, which is probably the best case scenario, I think they will just run into the same problems we have. So certainly the way I score, I would still much rather consider myself fortunate to be in the Western world in the United States. And we have this very deep problem of stagnation. I don't particularly want to move to China. You know, the best case, the absolute, almost utopian best case for China is that they just copy the U.S. and they end up where we are. And I tend to think my mid-case scenarios for them are much worse. that. Are there any areas that you think buck the trend and any technological fields that you don't see stagnation and that you see hope for that you're interested in? Well, look, I think there is a lot that can be done on a, you know, in some ways I was giving a big picture of history talk and then what's always somewhat intention is I always believe in human freedom, human agency, I believe that a lot more can be done. I invest in technologies, across many different fields. And so I have the strong conviction that these are not, it's not a law of nature that we've slowed down. And it's not that the cupboard has run out, or the cupboard is bare. You know, the argument I articulated was, was at its core, a cultural argument. It was the people are too scared. They've gotten too scared of technology. We could be doing a lot more. People are scared. I'm not, I'm trying to steal. I'm trying to say I understand why they're scared, but it is not a law of nature. It's just a cultural artifact of where we are. Returning to the very start of your speech, he said that you spoke about diversity and university being antonymical. Do you think this is necessarily the case on a practical rather than etymological level? And do you think that it's a result of society pursuing the wrong sorts of diversity? And if so why? There's so many polemical things. could say about it, probably, you know, I always like to say that, you know, you don't, you know, diversity is not merely hiring the extras from the space canteen scene in Star Wars. You want, you know, you don't want just a group of people who look different and think alike. And then, and then if you had, you know, if you had, you know, a genuine diversity of thought, of ideas, of viewpoints. I don't think that's inimical to, I know, a classic idea of a university as some sort of integrated, holistic search for truth. And my intuition is that somehow, you know, if these things worked as they did in some bygone golden age or might in some future golden age, it would somehow be involved genuine diversity on the level of the individuals and the professors and the researchers and the researchers and some genuine unity towards towards the truth. And the thing to underscore is that we probably have neither. You know, we neither have true diversity nor true university. And the sort of the sort of multicultural multiversity, it's a strange superposition of, you know, hyper-relativistic, hyper-nihialistic, hyper-totalitarian. And you will point out that those three things are all logically contradictory. And I can probably come up with some psychological analysis of why they go together, but that's, again, very complicated. Given that when you're at university a couple of decades ago, you wrote about the problems of political correctness, and now you talk about decline in the academy and in universities, do you think there is a point where this seemed to accelerate, or do you think it's all relative to the world around it? Well, these places are not completely isolated from the broader society, but But the piece that I did not connect when I was involved in these debates 30 years ago, I thought of these debates as sort of narrow ideological debates about the curriculum or about, you know, even broader historical debates about Western civilization or things like that. And I now think of them as somehow very, very deeply connected to this question of economic, scientific, technological progress. And in a society where, you know, there is a lot of progress happening where things are getting better, you can figure out some kind of a way that you have win-win solutions. Things don't need to be this Malthusian, this adversary. Well, if you have, you know, 10 postgraduate students in a chemistry lab where there's only job for one of them, and you have people having fistfights over beakers and bums and burners or whatever they have to do in a Malthusian world, then obviously if somebody says one politically incorrect thing and they get thrown off that overcrowded bus, that's a relief to the other nine people. So, yeah, I've come to think that at least large elements of it are linked to the sort of stagnation, Malthusian economics, things like that, which have a tendency to bring out the very worst in people. Last question before we move on from the Academy. do you think free speech is under threat at universities more than ever before, or do you think that the threat is not there or is abating? You know, I think it's under, I think it's under, I will not tell you anything that, yeah, you haven't heard many times before that I think it's under a great deal of threat, under a great deal of pressure. I always do wonder, though, what is it behind it? So even if we, you know, even if you had perfect free speech, even if the channels were all open, if the pipes were not clogged, what would actually be flowing through it? And I worry that these very ridiculous restrictions on free speech that we have are, you know, they're bad, we shouldn't have them, but they're also distracting us from the fact that people actually don't have very much to say. I hope not speaking for us that, Peter. Now, the promised question on currency, do you believe that PayPal and similar operations have, as you first claimed, given everyday people control of their currencies, or is this an unachieved aspiration? And might cryptocurrencies be the solution to that? Well, I was super into financial cryptography back in 1998 when I started PayPal. And there certainly, there was a sort of, um, there was a sort of, um, a classical liberal hope, maybe some would say a fantasy, that the computer age would decentralize things. It would sort of have these decentralizing things that would give more power to small businesses, to individuals, to all these different groups of people. And then there's obviously a way that, this sort of cypherpunk, crypto-anarchist, anarcho-libertarian hopes of the late 1990s in many ways, It seems like the pendulum swung the other way and that there was something about computer technology that was centralizing in the form of big companies, big tech, big governments. I don't think it's absolute intrinsic to computer technology itself. It's always possible for it for it to swing back. You know, big is an ambiguous word. It can mean strong or it can mean fat. and maybe and the cryptocurrencies represent the hope that things could go back the other way in various forms. But yes, if I had a bet on it, I would say we are at an extreme of centralization of tech and I would have some hope, not sure how grounded it is, that the pendulum could still swing back the other way. Before we open up to questions from the audience, moving on to politics. First question, why did you back President Trump in 2016, and do you regret it now? You should ask me this question 10 years or so. But I think the, you know, I think this, I backed Trump for the same reason that if I was in the UK, it would have been a pro-Brexit person. And it was just this very deep conviction that things are, were very off track. You know, our societies, they are too locked down, too stagnant. We need to change. You know, there are critiques I could give of myself where I, you know, it was some kind of scream for help. And then did that actually help bring about the kind of debate? I wanted to see about stagnation, how to move beyond stagnation. You know, I think the jury is still very out on that in the U.S. just as the Brexit debate, which in the UK you can think of as a debate about what's the identity of the UK. And the hope was that Brexit would sharpen that debate, would help form a better identity for Britain in the 21st century. And certainly for the first seven or eight years, there's a worry that both Trump and Brexit actually delayed. that much needed discussion more than they accelerated it. Why do you think that President Trump and I suppose Brexit and the candidates you've backed in elections since Trump have failed to bring about that disruption to the stagnation? Well, it's very hard to, you know, it's very hard to change. Look, there's a way that politics, there's a way that things like the Oxford Union are super important. There's one layer where you talk about it, and it's probably the most singularly inappropriate thing I could say here is that, you know, it's not all about talk. You know, it is sort of the, you know, it's in, you know, in the classical world, sophistry is the belief in the omnipotence of speech. And it's sort of like that's, that's supposed to be a monopoly of the biblical God. And somehow, you know, we always want to have somehow speech combined with action. We don't want to think that just saying the magic words is enough to trigger things. And so to the extent people had that conception about Brexit or Trump or about Obama giving a speech in Cairo, these were forms of sophistry, forms of belief in the omnipotence of speech. And in a very similar way, you know, the text stagnation problem that I touched on, you know, I can tell myself that giving a talk at the Oxford Union is a very small step towards it if I said that that was the panacea, wow, that would be insanely self-delusional. Might be better for our reputation, though. But, yeah, so talking about political donations in general, you're one of the largest political donors in America, and every election cycle, literally billions of dollars are spent on the presidential campaigns or congressional campaigns of both major parties, billions of dollars that could be used. to fund innovation, break the stagnation, or social projects, or in any number of ways. As a large political donor, do you think that a culture of political donation is healthy? The UK, in comparison, has very strict caps on the amount that political parties can spend, campaigning both locally and nationally. Should the US adopt similar laws? And if not, why not? Well, I don't think it's healthy for either of our societies to be as enmeshed in politics as they are. I think I always have a very schizophrenic view on it where I think it's toxic and unhealthy and at the same time it's all important because it permeates everything. So many of these problems won't have at least some political dimension to their solution. I don't know, challenging the premise of your question I would say it's shocking how little people spend on politics in the United States because you know it just permeates everything and you know it is so all important even if it's not the not the only vector for solving it and so i think uh yeah there's um and there probably there probably is something about the uk version of it where it means that uh um that if you if you can't do it these things just get displaced and in different in different forms and so if uh if individuals can't spend the money you know it means that you have even more power somehow uh resides in unelected bureaucracies and you know and we have some again i don't want to exaggerate the difference between UK and US, but it's, yeah, the problem is we are, we're in a world where it's just, it's just way too much politics. I would, I prefer to do away with it all together. That's too utopian. Political atheism. That's, that's an aspiration. But does a world with large levels of political donation, not just privilege individuals such as yourself who can invest in political projects that you care about, whilst not allowing that, level of political engagement that you said you should expect everyone to have given the importance of politics in everyday life? Oh, but you could say that about investing in science. You could say that about free speech, about media platforms. You could say that about all kinds of things. So then that just becomes a, you know, that just becomes a question about inequality, inequality generally. And, you know, and, and then I don't, I don't think inequality is our biggest problem. I think our biggest problem is stagnation. But science and technology and social media companies don't claim to have an equal buy in the same way that democracy and politics do. Yeah, but in democracy and politics, you have to still somehow convince people. It ends up being, you know, it ends up being, you know, a fairly competitive dynamic on where there's a lot of funding on both sides. It's kind of an arms race. So I'm, you know, certainly my, from my involvement, I, you know, there's, I would say it's always surprising, how hard it is to impact things. It's not like you can just spend money and people change their minds. The translation function is quite weak. You know, I would like it if you could translate things more. Again, not just in politics, but let's, you know, if I could just spend some of my money and get cures for cancer or could, you know, overcome these things. And unfortunately, it's mainly not a financial problem. It's a regulatory problem. It's a social problem. It's these other kinds of things. But, yeah, the translation function is shockingly weak. So the money doesn't solve the problems that you're identifying. You try to use it, but it is a shock. The translation function is shockingly weak. Have you ever, as a solution to that, considered getting involved directly in politics yourself and running for election? I'd go totally out of my mind if I did that. No. I've said too many things that are incompatible with that. On that note, I'm aware it's been a bit of a whistle stop tour of various topics. I want to very quickly open up questions to the audience. I'm sure there'll be a lot. I'm afraid to get through everyone. But if I call upon you, please wait whilst my colleague here brings you a microphone, stand up and ask Mr. Till your question. I call upon the, I'll remember in the black quarter zip in the front row. Hi, thank you so much for sharing your thoughts. The question that I have for you is that there are two things that I've learned. That first is that there's some parts of technology that you're excited about, some part you aren't, which is surprising. And second is that stagnation is not exciting to anyone. So in your personal capacity with someone who has the power, position, and money to either solve or influence these problems, how are you contributing to it? So I didn't quite hear the question. Could you repeat the question, please? The question is that in your personal capacity, how are you trying to solve the problem of stagnation? And secondly, there are some parts of technology that you're not happy about. Are you going about solving them with the investments that you've made? Sure. I'm not here to flog all my investments. But yes, my day job is I'm a venture capitalist, and I try to invest in business that are both successful and that somehow create major people. positive externalities for the world. And I've tried doing things in all these different verticals. It's quite hard outside of IT, outside of computers, but I've tried a wide range of these things, and that's probably my, that's the primary thing. And then secondarily, not zero percent, I also try talking about it like right now. The Honourable Member with the blonde hair, Go ahead. Hi, my name is Allison. Thank you for being here. In terms of your personal sense of free speech, in your writings that you've been doing for decades, I imagine your ideas evolved, do you ever regret anything that you've written? And if so, does that influence the way that you communicate and do you ever regret? or I'm sorry, have fear of future regret. Regret's sort of an ambiguous word. There are all sorts of things. There are all sorts of ways that speaking is dangerous. Writing is even more dangerous. You can, you know, I remember back in the 1980s it was one of these sort of conservative people, the Hoover Institution, told me that, you know, it was writing a book was a more dangerous undertaking than having a child. because if the child turned out badly, you could always disown your child, but you could never disown anything that you had written. And that struck me at the time as this slightly ridiculous academic perspective on the world. But yes, there's something about these things that's quite, you know, it's, there's something about that's uncomfortable, and I, you know, I don't know, I draw some balance in between. I probably say more than I should. and less than I might have a mind too. You'll remember in the grey sweatshirt, the front row here. Thank you. Given that the left dominates mainstream culture, why isn't the right producing more great art? What means? Why is it or why is it not? Why is it not producing more great art? Yeah, the right. I don't know, it's, it's, these, these things are, these things are all super hard to do. I, I, I, I, I, I mean, I always, I always am encouraging of people who do things. I'm, it's, it's not the sort of thing I, I, I know much about it all. Like, I have some idea of how to, how to produce, um, innovative tech companies, science companies. Um, but, but, uh, but, but, you know, it's, it's always, there's always a part of it, um, let me, Let me do one version on the Hollywood movie version where I've been, you know, I've gotten pulled into, you know, a number of these projects over the years. And there's always a somewhat stale conservative argument that, you know, it's all very biased. And it's, you know, it's a machine and they don't, they don't allow anybody with dissenting views to produce, to produce movies that don't fit the sort of center-left zombie straight jacket, or whatever you want to call it. And all of that may be true. But the problem is, you know, it's always an end. You need to do, it needs to still be very high quality. It's still extremely hard to do this. And when we frame these things too ideologically, that often becomes an excuse for, you know, losing sight of how hard it is to get the quality high enough. So yeah, I suspect, I don't know that much about the art world per se. I suspect it's a crazed, you know, left-wing racket. I believe that. And then I think most people who go to art school are just really lousy at it, and that includes most conservatives who are in art school. The Honorable and Perspective Calls Member in the third row here, the red scarf. Yeah. Hi, thanks. ALP doing an MSC in environmental sustainability and enterprise. I want to ask you a question on climate change and perhaps kindly push back on the statement that you made that the left or the greatest of the world do not advocate for technology-oriented solutions to climate, particularly given the Biden administration's recently passing of the Impration Reduction Act, the single biggest investment in climate ever, which provides hundreds of billions in incentives for hydrogen, EVs, storage, wind, solar, CCUS, all the above. So kind of given that, what is your solution to climate change and how does that align with the political donations that you've made in the US? And also I met Greta in person, and she can actually be quite lovely in person. Well, I think, it's a very, it's a very, It's a very multi-dimensional thing. I tend not to agree with the Marxist analysis of measuring input, so I don't care whether the government's spending tens of billions or hundreds of billions of dollars. I'd be interested in measuring output. And probably the very difficult challenge with energy technologies are you somehow want things that are cheaper, cleaner, you know, that somehow meet a lot of these criteria, and that's not quite what we're trending towards. And certainly my rough calibration of the energy around people concerned with climate change is that it has, it's about like 95% Luddite and about 5% you know, accelerationist. It's more keep the thermostat down and wear a sweater. And it's not really, we're going to invest in thorium to develop a third track of, along with uranium and plutonium for nuclear power technology. So I don't hear, I hear more excitement about wearing sweaters or riding bicycles than working on thorium plants. And then, and then, you know, and then you're not even allowed to, of course, comment on, if you comment on, you know, how the windmills don't seem to be the most efficient thing, then I end up being like Don Quixote or something like that. But probably time of one or two more questions. Do you want to remember with the Hart for College Scarf? Thank you. For disclosure, I'm a freelance reporter and Stringer. You and your companies have an extensive record investing in healthcare and biotech and Palantir is, as has been widely covered, pursuing a major NHS data contract, which is for you a great deal of opposition. The NHS being a major state operation, how would you fix it? Well, that's, man, that is, you know, it's always, you, these, all these, one of the thing is always tricky about all these political questions is there's sort of like a theory and practice, so in theory, there's sort of all sorts of things one would do very differently, And, you know, it's like, you know, what would you do if you're president of United States? And it's always the superposition of, you know, on the one hand, you're like the dictator. On the other hand, you're the mayor just kissing babies. So in theory, you're a dictator. In practice, you're a mayor kissing babies. And so in theory, I mean, you know, you just rip the whole thing from the ground out, start over. And in practice, you have to somehow make it all backwards compatible in all these, you know, ridiculous British ways in the case of the NHS. I suppose, again, I suppose the, you know, the first step, the thing that seems very odd for an outside observer of Britain is that, is this sort of Stockholm syndrome people have with respect to the NHS where it's like, it's like they think it is the most wonderful thing in the world. and perhaps, you know, perhaps the, you know, the first step is to just understand it as a very iatrogenic institution. You know, there's sort of probably some formula where we can go through, you know, all the institutions in our society and think of them as more iatrogenic than healthy. You know, the highways create traffic jams and welfare creates poverty and the schools make people dumb and the NHS makes people sick. And that's what I would start with. I would start by, well, like, I would use the, first step is you have to get out of the Stockholm syndrome that it's that it's that it's anywhere close to working and then yeah there are there are all kinds of there are all kinds of ways you would try to um you I mean you have to go into all the layers but you'd try to figure out ways to have market mechanisms you try to avoid rationing you try to you try to make it less regulated than it is that those would be those be my intuitions. When you say introduce market mechanisms, do you mean privatize further? You would try to find elements that you could privatize. You would try to, you know, obviously you, you know, we live in a society where you can't privatize these things completely, so, but even the parts that would be subsidized, you try to find market mechanisms even for the parts that are treated as a form of welfare. The CEO of NHS England is an ex-librarian of the union and is coming back this term, so we'll be sure to pass on your comments to her. I'm afraid I think that's all we have time for this evening, ladies and gentlemen. But before we thank Mr. Thiel for his time, I'll ask you the question we ask all of our speakers at the end of our talks, which is if you could give one piece of advice to the members of the Oxford Union and the students at the University of Oxford, what would that one piece of advice be? Well, it is sort of along the lines of what I've already articulated, which is always that, you know, these sorts of debates, discussions are absolutely important. They're sacred, but they are also just the first step. And we need a little bit more of the sort of Faust and Goethe where, you know, in the beginning is the deed. And we need talk, but also action. Ladies and gentlemen, please join me in thanking Mr. Peter Thiel. Thank you.